<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Ruby-spark by ondra-m</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Ruby-spark</h1>
        <p>Ruby wrapper for Apache Spark</p>

        <p class="view"><a href="https://github.com/ondra-m/ruby-spark">View the Project on GitHub <small>ondra-m/ruby-spark</small></a></p>


        <ul>
          <li><a href="https://github.com/ondra-m/ruby-spark/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/ondra-m/ruby-spark/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/ondra-m/ruby-spark">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <p>In this post, I describe how to parallelize computations in Ruby with <strong>ruby-spark</strong> gem. This library uses a Apache Spark project to storing and distributing data collections across cluster.</p>

<p>Requirments:</p>

<ul>
<li>Java 7+</li>
<li>Ruby 2+</li>
<li>MRI or JRuby</li>
</ul>

<p>Glossary:</p>

<ul>
<li>Context: entry point for using Spark functionality</li>
<li>RDD: Resilient Distributed Dataset</li>
<li>Driver: a driver Spark instance (exist only once)</li>
<li>Executor: worker instance</li>
</ul>

<p><img src="http://spark.apache.org/docs/latest/img/cluster-overview.png" alt="Apache Spark cluster"></p>

<h2>
<a id="installation" class="anchor" href="#installation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Installation</h2>

<div class="highlight highlight-bash"><pre><span class="pl-c"># Install gem</span>
gem install ruby-spark

<span class="pl-c"># Build Spark and extensions (could take a while)</span>
ruby-spark build

<span class="pl-c"># Set JAVA_HOME (required for MRI)</span>
<span class="pl-k">export</span> JAVA_HOME=<span class="pl-s"><span class="pl-pds">"</span>...<span class="pl-pds">"</span></span></pre></div>

<h2>
<a id="starting-and-configurations" class="anchor" href="#starting-and-configurations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Starting and configurations</h2>

<p>For all setup options, please look on <a href="https://github.com/ondra-m/ruby-spark/wiki/Configuration">wiki</a>. All necessary configuration are set by default but if you want change it you need set keys before creating context. After that is configuration read-only.</p>

<div class="highlight highlight-ruby"><pre><span class="pl-k">require</span> <span class="pl-s"><span class="pl-pds">'</span>ruby-spark<span class="pl-pds">'</span></span>

<span class="pl-c"># Configuration</span>
<span class="pl-c1">Spark</span>.config <span class="pl-k">do</span>
  set_app_name <span class="pl-s"><span class="pl-pds">'</span>My RubySpark<span class="pl-pds">'</span></span>
  set_master   <span class="pl-s"><span class="pl-pds">'</span>local[*]<span class="pl-pds">'</span></span>
  set <span class="pl-s"><span class="pl-pds">'</span>spark.ruby.batch_size<span class="pl-pds">'</span></span>, <span class="pl-c1">2048</span>
<span class="pl-k">end</span>

<span class="pl-c"># Create a context</span>
<span class="pl-c1">Spark</span>.start

<span class="pl-c"># Context reference</span>
sc <span class="pl-k">=</span> <span class="pl-c1">Spark</span>.sc</pre></div>

<p>You can also start prepared console by <code>ruby-spark shell</code>. This command will load RubySpark and create Pry console.</p>

<h2>
<a id="usage" class="anchor" href="#usage" aria-hidden="true"><span class="octicon octicon-link"></span></a>Usage</h2>

<p>First, you need create a distributed data collection. This dataset will be splitted into computing process. All process have the same computing function and cannot comunicate with each other.</p>

<div class="highlight highlight-ruby"><pre>worker_nums <span class="pl-k">=</span> <span class="pl-c1">2</span>
rands <span class="pl-k">=</span> <span class="pl-c1">Array</span>.<span class="pl-k">new</span>(<span class="pl-c1">1000</span>){ rand(<span class="pl-c1">1</span>..<span class="pl-c1">10</span>) }

rdd_numbers <span class="pl-k">=</span> sc.parallelize(<span class="pl-c1">1</span>..<span class="pl-c1">1000</span>, worker_nums)
rdd_rands <span class="pl-k">=</span> sc.parallelize(rands, worker_nums)
text_file <span class="pl-k">=</span> sc.text_file(<span class="pl-s"><span class="pl-pds">'</span>/etc/hosts<span class="pl-pds">'</span></span>, worker_nums)</pre></div>

<p>Now you can define a computing function. All function can be found at <a href="http://www.rubydoc.info/github/ondra-m/ruby-spark/Spark/RDD">ruby-doc</a>. Every new function is attached to dataset and are executed at once by <code>.collect</code> (lazy definition). However some methods start calculation automatically (e.g. sum, count, first, ...).</p>

<div class="highlight highlight-ruby"><pre><span class="pl-c"># Simple map</span>
rdd <span class="pl-k">=</span> rdd_numbers.map(lambda{|<span class="pl-smi">x</span>| x<span class="pl-k">*</span><span class="pl-c1">2</span>}).collect <span class="pl-c"># =&gt; [2, 4, 6, 8, 10, 12, ...]</span>

<span class="pl-c"># Pipelined methods</span>
func <span class="pl-k">=</span> lambda <span class="pl-k">do </span>|<span class="pl-smi">iterator</span>|
  iterator.map { |(<span class="pl-smi">modulo</span>, <span class="pl-smi">max</span>)|
    <span class="pl-s"><span class="pl-pds">"</span>Modulo: <span class="pl-pse">#{</span><span class="pl-s1">modulo</span><span class="pl-pse"><span class="pl-s1">}</span></span> have max <span class="pl-pse">#{</span><span class="pl-s1">max</span><span class="pl-pse"><span class="pl-s1">}</span></span>.<span class="pl-pds">"</span></span>
  }
<span class="pl-k">end</span>

rdd <span class="pl-k">=</span> rdd_rands.map(<span class="pl-c1">:to_f</span>)          <span class="pl-c"># `.to_f` will be called on ever item</span>
rdd <span class="pl-k">=</span> rdd.filter(lambda{|<span class="pl-smi">x</span>| x <span class="pl-k">&gt;</span> <span class="pl-c1">2</span>}) <span class="pl-c"># select items greater than 2</span>
rdd <span class="pl-k">=</span> rdd.group_by(lambda{|<span class="pl-smi">x</span>| x<span class="pl-k">%</span><span class="pl-c1">2</span>}) <span class="pl-c"># group items based on modulo</span>
rdd <span class="pl-k">=</span> rdd.map_values(<span class="pl-c1">:max</span>)          <span class="pl-c"># get max from values</span>
rdd <span class="pl-k">=</span> rdd.map_partitions(func)      <span class="pl-c"># map on whole iterator</span>
rdd.collect <span class="pl-c"># =&gt; ["Modulo: 1.0 have max 7.0.", "Modulo: 0.0 have max 8.0."]</span>

<span class="pl-c"># Word count</span>
words <span class="pl-k">=</span> text_file.flat_map(<span class="pl-c1">:split</span>)
arrays <span class="pl-k">=</span> words.map(lambda{|<span class="pl-smi">word</span>| [word, <span class="pl-c1">1</span>]})
count <span class="pl-k">=</span> arrays.reduce_by_key(lambda{|<span class="pl-smi">a</span>, <span class="pl-smi">b</span>| a<span class="pl-k">+</span>b})
count.collect <span class="pl-c"># =&gt; [["127.0.0.1", 1], ["localhost", 1], ["#", 3], ...]</span>

<span class="pl-c"># PI</span>
rdd <span class="pl-k">=</span> sc.parallelize([<span class="pl-c1">10_000</span>], <span class="pl-c1">1</span>)
rdd <span class="pl-k">=</span> rdd.add_library(<span class="pl-s"><span class="pl-pds">'</span>bigdecimal/math<span class="pl-pds">'</span></span>)
rdd <span class="pl-k">=</span> rdd.map(lambda{|<span class="pl-smi">x</span>| <span class="pl-c1">BigMath</span>.<span class="pl-c1">PI</span>(x)})
rdd.collect <span class="pl-c"># =&gt; #&lt;BigDecimal, '0.31415926...'&gt;</span>

<span class="pl-c"># Stats</span>
rdd <span class="pl-k">=</span> rdd_numbers.map(lambda{|<span class="pl-smi">x</span>| (x <span class="pl-k">*</span> rand) <span class="pl-k">**</span> <span class="pl-c1">2</span>})
stats <span class="pl-k">=</span> rdd.stats <span class="pl-c"># =&gt; StatCounter</span>

stats.min
stats.max
stats.count
stats.mean
stats.stdev
stats.variance
stats.sample_stdev
stats.sample_variance</pre></div>

<p>Github: <a href="https://github.com/ondra-m/ruby-spark">https://github.com/ondra-m/ruby-spark</a></p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/ondra-m">ondra-m</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>